{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "covid.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TeKJ1eknvL2U",
        "f4JT7LjE0dyC",
        "z-xvAaOtvBqn",
        "-ihF-FLvvVvY",
        "NzjW3_ekuDs3",
        "bNnaQbkFt2sm",
        "KgcnKB1vt9jD",
        "ODJE3OZ50vOY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/notomasz/MZ/blob/master/covid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeKJ1eknvL2U"
      },
      "source": [
        "### **Normalizacja rozmiaru zdjęć**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq19jqDNBGQt"
      },
      "source": [
        "import PIL\n",
        "import os\n",
        "import os.path\n",
        "from PIL import Image\n",
        "\n",
        "f = r'/content/drive/My Drive/data/'\n",
        "fs = r'/content/drive/My Drive/data/'\n",
        "for file in os.listdir(f):\n",
        "    f_img = f+\"/\"+file\n",
        "    img = Image.open(f_img)\n",
        "    img = img.resize((224,224))\n",
        "    img.save(fs+'/'+file, \"PNG\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4JT7LjE0dyC"
      },
      "source": [
        "### **Wczytanie bibliotek**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKuqakfkLZ_j"
      },
      "source": [
        "#instalacja\n",
        "!pip install tf-nightly\n",
        "\n",
        "#google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',  force_remount=True)\n",
        "\n",
        "#numpy, pandas, matplotlib, seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "#tensorflow/keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import (Input, Dense, Dropout, Conv2D, MaxPooling2D, Activation, BatchNormalization, Flatten, add, GlobalAveragePooling2D)\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.metrics import binary_accuracy\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications import Xception\n",
        "from keras.applications import ResNet50V2\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "#sklearn\n",
        "from sklearn.metrics import f1_score, roc_auc_score, classification_report, confusion_matrix\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import precision_recall_curve, auc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-xvAaOtvBqn"
      },
      "source": [
        "### **Zdefiniowanie funkcji oraz zmiennych globalnych**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wREwM8YezzCd"
      },
      "source": [
        "def print_layers(model):\n",
        "    for idx, layer in enumerate(model.layers):\n",
        "        print(\"layer {}: {}, trainable: {}\".format(idx, layer.name, layer.trainable))\n",
        "\n",
        "def summary(y_test, y_pred):\n",
        "  auc = roc_auc_score(y_test, y_pred)\n",
        "  ax2 = plt.figure(figsize=(12,8))\n",
        "  fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "  plt.plot(fpr, tpr, label='Model (area = %0.2f)' % auc, c='#1f77b4')\n",
        "  plt.plot([0, 1], [0, 1],'r--')\n",
        "  plt.xlabel('1 - specyficzność')\n",
        "  plt.ylabel('Czułość')\n",
        "  #plt.title('Receiver operating characteristic')\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  ax = plt.figure(figsize=(12,8))\n",
        "  cm = confusion_matrix(y_test, y_pred)\n",
        "  sns.set(font_scale=1.3)\n",
        "  ax = sns.heatmap(cm, vmin=0, vmax=500,annot=True,linewidths=.1, fmt='d', cmap='Blues', xticklabels=['nie-covid', 'covid'], yticklabels=['nie-covid', 'covid'])\n",
        "  plt.xlabel(\"Klasa predykowana\",)\n",
        "  plt.ylabel(\"Klasa właściwa\")\n",
        "  tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "  accuracy= (tp+tn)/ (tp+tn+fp+fn) * 100\n",
        "  specificity = tn/(tn+fp) * 100\n",
        "  sensitivity = tp/(tp+fn) * 100\n",
        "  precision = tp/(tp+fp) * 100\n",
        "  f1score = f1_score(y_test, y_pred) * 100\n",
        "  print('Accuracy: {}\\nSensitivity: {}\\nSpecificity: {}\\nAUC: {}\\nF1_score: {}\\nPrecision: {}'.format(accuracy, sensitivity, specificity, auc, f1score, precision))\n",
        "  return ax, ax2\n",
        "\n",
        "def create_model(model_name, lr, dropout):\n",
        "  model = Sequential()\n",
        "  model.add(model_name)\n",
        "  model.add(Dense(512, activation='relu', input_dim=(2663,100352), name='Warstwa_gesta_1'))\n",
        "  model.add(Dropout(dropout, name='Porzucenie_1'))\n",
        "  model.add(Dense(512, activation='relu', name='Warstwa_gesta_2'))\n",
        "  model.add(Dropout(dropout, name='Porzucenie_2'))\n",
        "  model.add(Dense(256, activation='relu', name='Warstwa_gesta_3'))\n",
        "  model.add(Dense(128, activation='relu', name='Warstwa_gesta_4'))\n",
        "  model.add(Dense(1, activation='sigmoid', name='Warstwa_wyjsciowa'))\n",
        "\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                optimizer=Adam(lr=lr),\n",
        "                metrics=['binary_accuracy'])\n",
        "  return model\n",
        "\n",
        "#rozmiar danych wejsciowych\n",
        "input_shape=(224,224,3)\n",
        "\n",
        "#wagi klas\n",
        "class_weight = {0:1, 1:3.01659125189}\n",
        "\n",
        "#zapisywanie modeli oraz przerywanie uczenia\n",
        "callbacks_list_1 = [EarlyStopping(monitor='val_loss', patience=10),\n",
        "        ModelCheckpoint(filepath='/content/drive/My Drive/saved_models/Xception_1.h5', monitor='val_loss', save_best_only=True, mode='min')]\n",
        "\n",
        "callbacks_list_2 = [EarlyStopping(monitor='val_loss', patience=10),\n",
        "        ModelCheckpoint(filepath='/content/drive/My Drive/saved_models/Xception_2.h5', monitor='val_loss', save_best_only=True, mode='min')]\n",
        "\n",
        "callbacks_list_3 = [EarlyStopping(monitor='val_loss', patience=10),\n",
        "        ModelCheckpoint(filepath='/content/drive/My Drive/saved_models/ResNet_1.h5', monitor='val_loss', save_best_only=True, mode='min')]\n",
        "\n",
        "callbacks_list_4 = [EarlyStopping(monitor='val_loss', patience=10),\n",
        "        ModelCheckpoint(filepath='/content/drive/My Drive/saved_models/ResNet_2.h5', monitor='val_loss', save_best_only=True, mode='min')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ihF-FLvvVvY"
      },
      "source": [
        "### **Zdefiniowanie parametrów augmentacji**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MALjDTJZ1xA",
        "outputId": "2be7483b-bd0f-40c7-e280-3dd878ae77d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, zoom_range=0.1, rotation_range=10,\n",
        "                                   width_shift_range=0.10, shear_range=0.1, \n",
        "                                   horizontal_flip=True, fill_mode='nearest')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/final_resized/train/',\n",
        "    class_mode=\"binary\",\n",
        "    #class_names=['covid', 'non'],\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=64,\n",
        "    target_size=(224, 224),\n",
        "    shuffle=True,\n",
        "    seed=111,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        ")\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/final_resized/validation/',\n",
        "    class_mode=\"binary\",\n",
        "    #class_names=['covid', 'non'],\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=64,\n",
        "    target_size=(224, 224),\n",
        "    shuffle=True,\n",
        "    seed=111,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        ")\n",
        "\n",
        "test_generator = val_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/final_resized/test/',\n",
        "    class_mode=\"binary\",\n",
        "    #class_names=['covid', 'non'],\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=64,\n",
        "    target_size=(224, 224),\n",
        "    shuffle=False,\n",
        "    seed=111,\n",
        "    subset=None,\n",
        "    interpolation=\"bilinear\",\n",
        "    follow_links=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2663 images belonging to 2 classes.\n",
            "Found 50 images belonging to 2 classes.\n",
            "Found 2800 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNImPYXQz_2u"
      },
      "source": [
        "### **Xception**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o79xPWjUuFzD"
      },
      "source": [
        "#### ostatni moduł"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xnz1ItcoElCg"
      },
      "source": [
        "xception = Xception(include_top=False, weights='imagenet', \n",
        "                                     input_shape=input_shape, pooling='max')\n",
        "\n",
        "output = xception.layers[-1].output\n",
        "output = Flatten()(output)\n",
        "xception_model = Model(xception.input, output, name='Baza_konwolucyjna')\n",
        "\n",
        "xception_model.trainable = True\n",
        "for layer in xception_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "#bottleneck_feature_example = res.predict(x_train.take(21))\n",
        "#print(bottleneck_feature_example.shape)\n",
        "#plt.imshow(bottleneck_feature_example[0][:,:,0])\n",
        "\n",
        "for layer in xception_model.layers[-8:]:\n",
        "  layer.trainable=True\n",
        "print_layers(xception_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38X5H8JOpORU",
        "outputId": "78c6af6c-0a3b-4276-ffce-d243fb9ca492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "xception_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Baza_konwolucyjna\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, 111, 111, 32) 864         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, 111, 111, 32) 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, 111, 111, 32) 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, 109, 109, 64) 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, 109, 109, 64) 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, 109, 109, 64) 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, 109, 109, 128 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, 109, 109, 128 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, 109, 109, 128 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 55, 55, 128)  8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, 55, 55, 128)  0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 55, 55, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_48 (Add)                    (None, 55, 55, 128)  0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, 55, 55, 128)  0           add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, 55, 55, 256)  33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, 55, 55, 256)  0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, 55, 55, 256)  67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 28, 28, 256)  32768       add_48[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 28, 28, 256)  1024        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_49 (Add)                    (None, 28, 28, 256)  0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, 28, 28, 256)  0           add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, 28, 28, 728)  188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, 28, 28, 728)  0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, 28, 28, 728)  536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 14, 14, 728)  186368      add_49[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, 14, 14, 728)  0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 14, 14, 728)  2912        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_50 (Add)                    (None, 14, 14, 728)  0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, 14, 14, 728)  0           add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, 14, 14, 728)  0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, 14, 14, 728)  0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_51 (Add)                    (None, 14, 14, 728)  0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_50[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, 14, 14, 728)  0           add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, 14, 14, 728)  0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, 14, 14, 728)  0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_52 (Add)                    (None, 14, 14, 728)  0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_51[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, 14, 14, 728)  0           add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, 14, 14, 728)  0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, 14, 14, 728)  0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_53 (Add)                    (None, 14, 14, 728)  0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_52[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, 14, 14, 728)  0           add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, 14, 14, 728)  0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, 14, 14, 728)  0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_54 (Add)                    (None, 14, 14, 728)  0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_53[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, 14, 14, 728)  0           add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, 14, 14, 728)  0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, 14, 14, 728)  0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_55 (Add)                    (None, 14, 14, 728)  0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_54[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, 14, 14, 728)  0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, 14, 14, 728)  0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_56 (Add)                    (None, 14, 14, 728)  0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_55[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, 14, 14, 728)  0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, 14, 14, 728)  0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_57 (Add)                    (None, 14, 14, 728)  0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_56[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, 14, 14, 728)  0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, 14, 14, 728)  0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_58 (Add)                    (None, 14, 14, 728)  0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_57[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, 14, 14, 728)  0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, 14, 14, 1024) 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, 14, 14, 1024) 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 7, 7, 1024)   745472      add_58[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 7, 7, 1024)   4096        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_59 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_59[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "global_max_pooling2d_2 (GlobalM (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 2048)         0           global_max_pooling2d_2[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 20,861,480\n",
            "Trainable params: 4,748,800\n",
            "Non-trainable params: 16,112,680\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzjW3_ekuDs3"
      },
      "source": [
        "#### dwa ostatnie moduły"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ4ItdpDr6s0"
      },
      "source": [
        "xception2 = Xception(include_top=False, weights='imagenet', \n",
        "                                     input_shape=input_shape)\n",
        "\n",
        "output = xception2.layers[-1].output\n",
        "output = Flatten()(output)\n",
        "xception_model2= Model(xception2.input, output, name='Baza_konwolucyjna')\n",
        "\n",
        "xception_model2.trainable = True\n",
        "for layer in xception_model2.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "#bottleneck_feature_example = res.predict(x_train.take(21))\n",
        "#print(bottleneck_feature_example.shape)\n",
        "#plt.imshow(bottleneck_feature_example[0][:,:,0])\n",
        "\n",
        "for layer in xception_model2.layers[-27:]:\n",
        "  layer.trainable=True\n",
        "print_layers(xception_model2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4y2CU3U0r3q"
      },
      "source": [
        "### **ResNet**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNnaQbkFt2sm"
      },
      "source": [
        "##### ostatni moduł"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPydbnlG0uQl"
      },
      "source": [
        "res = ResNet50V2(include_top=False, weights='imagenet', \n",
        "                                     input_shape=input_shape)\n",
        "\n",
        "output = res.layers[-1].output\n",
        "#output = GlobalAveragePooling2D()(output)\n",
        "output = Flatten()(output)\n",
        "res_model = Model(res.input, output ,name='Baza_konwolucyjna')\n",
        "\n",
        "res_model.trainable = True\n",
        "for layer in res_model.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "\n",
        "#bottleneck_feature_example = res.predict(x_train.take(5))\n",
        "#print(bottleneck_feature_example.shape)\n",
        "#plt.imshow(bottleneck_feature_example[0][:,:,0])\n",
        "\n",
        "for layer in res_model.layers[-14:]:\n",
        "  layer.trainable=True\n",
        "print_layers(res_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgcnKB1vt9jD"
      },
      "source": [
        "#### dwa ostatnie moduły"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRJWlCZero3Y",
        "outputId": "092a61d6-299f-47df-a25d-350cdea8dc74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "res2 = ResNet50V2(include_top=False, weights='imagenet', \n",
        "                                     input_shape=input_shape)\n",
        "\n",
        "output = res2.layers[-1].output\n",
        "#output = GlobalAveragePooling2D()(output)\n",
        "output = Flatten()(output)\n",
        "res_model2 = Model(res2.input, output ,name='Baza_konwolucyjna')\n",
        "\n",
        "res_model2.trainable = True\n",
        "for layer in res_model2.layers:\n",
        "    layer.trainable = False\n",
        "    \n",
        "#bottleneck_feature_example = res.predict(x_train.take(1))\n",
        "#print(bottleneck_feature_example.shape)\n",
        "#plt.imshow(bottleneck_feature_example[0][:,:,0])\n",
        "\n",
        "for layer in res_model2.layers[-25:]:\n",
        "  layer.trainable=True\n",
        "print_layers(res_model2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer 0: input_2, trainable: False\n",
            "layer 1: conv1_pad, trainable: False\n",
            "layer 2: conv1_conv, trainable: False\n",
            "layer 3: pool1_pad, trainable: False\n",
            "layer 4: pool1_pool, trainable: False\n",
            "layer 5: conv2_block1_preact_bn, trainable: False\n",
            "layer 6: conv2_block1_preact_relu, trainable: False\n",
            "layer 7: conv2_block1_1_conv, trainable: False\n",
            "layer 8: conv2_block1_1_bn, trainable: False\n",
            "layer 9: conv2_block1_1_relu, trainable: False\n",
            "layer 10: conv2_block1_2_pad, trainable: False\n",
            "layer 11: conv2_block1_2_conv, trainable: False\n",
            "layer 12: conv2_block1_2_bn, trainable: False\n",
            "layer 13: conv2_block1_2_relu, trainable: False\n",
            "layer 14: conv2_block1_0_conv, trainable: False\n",
            "layer 15: conv2_block1_3_conv, trainable: False\n",
            "layer 16: conv2_block1_out, trainable: False\n",
            "layer 17: conv2_block2_preact_bn, trainable: False\n",
            "layer 18: conv2_block2_preact_relu, trainable: False\n",
            "layer 19: conv2_block2_1_conv, trainable: False\n",
            "layer 20: conv2_block2_1_bn, trainable: False\n",
            "layer 21: conv2_block2_1_relu, trainable: False\n",
            "layer 22: conv2_block2_2_pad, trainable: False\n",
            "layer 23: conv2_block2_2_conv, trainable: False\n",
            "layer 24: conv2_block2_2_bn, trainable: False\n",
            "layer 25: conv2_block2_2_relu, trainable: False\n",
            "layer 26: conv2_block2_3_conv, trainable: False\n",
            "layer 27: conv2_block2_out, trainable: False\n",
            "layer 28: conv2_block3_preact_bn, trainable: False\n",
            "layer 29: conv2_block3_preact_relu, trainable: False\n",
            "layer 30: conv2_block3_1_conv, trainable: False\n",
            "layer 31: conv2_block3_1_bn, trainable: False\n",
            "layer 32: conv2_block3_1_relu, trainable: False\n",
            "layer 33: conv2_block3_2_pad, trainable: False\n",
            "layer 34: conv2_block3_2_conv, trainable: False\n",
            "layer 35: conv2_block3_2_bn, trainable: False\n",
            "layer 36: conv2_block3_2_relu, trainable: False\n",
            "layer 37: max_pooling2d_3, trainable: False\n",
            "layer 38: conv2_block3_3_conv, trainable: False\n",
            "layer 39: conv2_block3_out, trainable: False\n",
            "layer 40: conv3_block1_preact_bn, trainable: False\n",
            "layer 41: conv3_block1_preact_relu, trainable: False\n",
            "layer 42: conv3_block1_1_conv, trainable: False\n",
            "layer 43: conv3_block1_1_bn, trainable: False\n",
            "layer 44: conv3_block1_1_relu, trainable: False\n",
            "layer 45: conv3_block1_2_pad, trainable: False\n",
            "layer 46: conv3_block1_2_conv, trainable: False\n",
            "layer 47: conv3_block1_2_bn, trainable: False\n",
            "layer 48: conv3_block1_2_relu, trainable: False\n",
            "layer 49: conv3_block1_0_conv, trainable: False\n",
            "layer 50: conv3_block1_3_conv, trainable: False\n",
            "layer 51: conv3_block1_out, trainable: False\n",
            "layer 52: conv3_block2_preact_bn, trainable: False\n",
            "layer 53: conv3_block2_preact_relu, trainable: False\n",
            "layer 54: conv3_block2_1_conv, trainable: False\n",
            "layer 55: conv3_block2_1_bn, trainable: False\n",
            "layer 56: conv3_block2_1_relu, trainable: False\n",
            "layer 57: conv3_block2_2_pad, trainable: False\n",
            "layer 58: conv3_block2_2_conv, trainable: False\n",
            "layer 59: conv3_block2_2_bn, trainable: False\n",
            "layer 60: conv3_block2_2_relu, trainable: False\n",
            "layer 61: conv3_block2_3_conv, trainable: False\n",
            "layer 62: conv3_block2_out, trainable: False\n",
            "layer 63: conv3_block3_preact_bn, trainable: False\n",
            "layer 64: conv3_block3_preact_relu, trainable: False\n",
            "layer 65: conv3_block3_1_conv, trainable: False\n",
            "layer 66: conv3_block3_1_bn, trainable: False\n",
            "layer 67: conv3_block3_1_relu, trainable: False\n",
            "layer 68: conv3_block3_2_pad, trainable: False\n",
            "layer 69: conv3_block3_2_conv, trainable: False\n",
            "layer 70: conv3_block3_2_bn, trainable: False\n",
            "layer 71: conv3_block3_2_relu, trainable: False\n",
            "layer 72: conv3_block3_3_conv, trainable: False\n",
            "layer 73: conv3_block3_out, trainable: False\n",
            "layer 74: conv3_block4_preact_bn, trainable: False\n",
            "layer 75: conv3_block4_preact_relu, trainable: False\n",
            "layer 76: conv3_block4_1_conv, trainable: False\n",
            "layer 77: conv3_block4_1_bn, trainable: False\n",
            "layer 78: conv3_block4_1_relu, trainable: False\n",
            "layer 79: conv3_block4_2_pad, trainable: False\n",
            "layer 80: conv3_block4_2_conv, trainable: False\n",
            "layer 81: conv3_block4_2_bn, trainable: False\n",
            "layer 82: conv3_block4_2_relu, trainable: False\n",
            "layer 83: max_pooling2d_4, trainable: False\n",
            "layer 84: conv3_block4_3_conv, trainable: False\n",
            "layer 85: conv3_block4_out, trainable: False\n",
            "layer 86: conv4_block1_preact_bn, trainable: False\n",
            "layer 87: conv4_block1_preact_relu, trainable: False\n",
            "layer 88: conv4_block1_1_conv, trainable: False\n",
            "layer 89: conv4_block1_1_bn, trainable: False\n",
            "layer 90: conv4_block1_1_relu, trainable: False\n",
            "layer 91: conv4_block1_2_pad, trainable: False\n",
            "layer 92: conv4_block1_2_conv, trainable: False\n",
            "layer 93: conv4_block1_2_bn, trainable: False\n",
            "layer 94: conv4_block1_2_relu, trainable: False\n",
            "layer 95: conv4_block1_0_conv, trainable: False\n",
            "layer 96: conv4_block1_3_conv, trainable: False\n",
            "layer 97: conv4_block1_out, trainable: False\n",
            "layer 98: conv4_block2_preact_bn, trainable: False\n",
            "layer 99: conv4_block2_preact_relu, trainable: False\n",
            "layer 100: conv4_block2_1_conv, trainable: False\n",
            "layer 101: conv4_block2_1_bn, trainable: False\n",
            "layer 102: conv4_block2_1_relu, trainable: False\n",
            "layer 103: conv4_block2_2_pad, trainable: False\n",
            "layer 104: conv4_block2_2_conv, trainable: False\n",
            "layer 105: conv4_block2_2_bn, trainable: False\n",
            "layer 106: conv4_block2_2_relu, trainable: False\n",
            "layer 107: conv4_block2_3_conv, trainable: False\n",
            "layer 108: conv4_block2_out, trainable: False\n",
            "layer 109: conv4_block3_preact_bn, trainable: False\n",
            "layer 110: conv4_block3_preact_relu, trainable: False\n",
            "layer 111: conv4_block3_1_conv, trainable: False\n",
            "layer 112: conv4_block3_1_bn, trainable: False\n",
            "layer 113: conv4_block3_1_relu, trainable: False\n",
            "layer 114: conv4_block3_2_pad, trainable: False\n",
            "layer 115: conv4_block3_2_conv, trainable: False\n",
            "layer 116: conv4_block3_2_bn, trainable: False\n",
            "layer 117: conv4_block3_2_relu, trainable: False\n",
            "layer 118: conv4_block3_3_conv, trainable: False\n",
            "layer 119: conv4_block3_out, trainable: False\n",
            "layer 120: conv4_block4_preact_bn, trainable: False\n",
            "layer 121: conv4_block4_preact_relu, trainable: False\n",
            "layer 122: conv4_block4_1_conv, trainable: False\n",
            "layer 123: conv4_block4_1_bn, trainable: False\n",
            "layer 124: conv4_block4_1_relu, trainable: False\n",
            "layer 125: conv4_block4_2_pad, trainable: False\n",
            "layer 126: conv4_block4_2_conv, trainable: False\n",
            "layer 127: conv4_block4_2_bn, trainable: False\n",
            "layer 128: conv4_block4_2_relu, trainable: False\n",
            "layer 129: conv4_block4_3_conv, trainable: False\n",
            "layer 130: conv4_block4_out, trainable: False\n",
            "layer 131: conv4_block5_preact_bn, trainable: False\n",
            "layer 132: conv4_block5_preact_relu, trainable: False\n",
            "layer 133: conv4_block5_1_conv, trainable: False\n",
            "layer 134: conv4_block5_1_bn, trainable: False\n",
            "layer 135: conv4_block5_1_relu, trainable: False\n",
            "layer 136: conv4_block5_2_pad, trainable: False\n",
            "layer 137: conv4_block5_2_conv, trainable: False\n",
            "layer 138: conv4_block5_2_bn, trainable: False\n",
            "layer 139: conv4_block5_2_relu, trainable: False\n",
            "layer 140: conv4_block5_3_conv, trainable: False\n",
            "layer 141: conv4_block5_out, trainable: False\n",
            "layer 142: conv4_block6_preact_bn, trainable: False\n",
            "layer 143: conv4_block6_preact_relu, trainable: False\n",
            "layer 144: conv4_block6_1_conv, trainable: False\n",
            "layer 145: conv4_block6_1_bn, trainable: False\n",
            "layer 146: conv4_block6_1_relu, trainable: False\n",
            "layer 147: conv4_block6_2_pad, trainable: False\n",
            "layer 148: conv4_block6_2_conv, trainable: False\n",
            "layer 149: conv4_block6_2_bn, trainable: False\n",
            "layer 150: conv4_block6_2_relu, trainable: False\n",
            "layer 151: max_pooling2d_5, trainable: False\n",
            "layer 152: conv4_block6_3_conv, trainable: False\n",
            "layer 153: conv4_block6_out, trainable: False\n",
            "layer 154: conv5_block1_preact_bn, trainable: False\n",
            "layer 155: conv5_block1_preact_relu, trainable: False\n",
            "layer 156: conv5_block1_1_conv, trainable: False\n",
            "layer 157: conv5_block1_1_bn, trainable: False\n",
            "layer 158: conv5_block1_1_relu, trainable: False\n",
            "layer 159: conv5_block1_2_pad, trainable: False\n",
            "layer 160: conv5_block1_2_conv, trainable: False\n",
            "layer 161: conv5_block1_2_bn, trainable: False\n",
            "layer 162: conv5_block1_2_relu, trainable: False\n",
            "layer 163: conv5_block1_0_conv, trainable: False\n",
            "layer 164: conv5_block1_3_conv, trainable: False\n",
            "layer 165: conv5_block1_out, trainable: False\n",
            "layer 166: conv5_block2_preact_bn, trainable: True\n",
            "layer 167: conv5_block2_preact_relu, trainable: True\n",
            "layer 168: conv5_block2_1_conv, trainable: True\n",
            "layer 169: conv5_block2_1_bn, trainable: True\n",
            "layer 170: conv5_block2_1_relu, trainable: True\n",
            "layer 171: conv5_block2_2_pad, trainable: True\n",
            "layer 172: conv5_block2_2_conv, trainable: True\n",
            "layer 173: conv5_block2_2_bn, trainable: True\n",
            "layer 174: conv5_block2_2_relu, trainable: True\n",
            "layer 175: conv5_block2_3_conv, trainable: True\n",
            "layer 176: conv5_block2_out, trainable: True\n",
            "layer 177: conv5_block3_preact_bn, trainable: True\n",
            "layer 178: conv5_block3_preact_relu, trainable: True\n",
            "layer 179: conv5_block3_1_conv, trainable: True\n",
            "layer 180: conv5_block3_1_bn, trainable: True\n",
            "layer 181: conv5_block3_1_relu, trainable: True\n",
            "layer 182: conv5_block3_2_pad, trainable: True\n",
            "layer 183: conv5_block3_2_conv, trainable: True\n",
            "layer 184: conv5_block3_2_bn, trainable: True\n",
            "layer 185: conv5_block3_2_relu, trainable: True\n",
            "layer 186: conv5_block3_3_conv, trainable: True\n",
            "layer 187: conv5_block3_out, trainable: True\n",
            "layer 188: post_bn, trainable: True\n",
            "layer 189: post_relu, trainable: True\n",
            "layer 190: flatten_1, trainable: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKKGWK15aUpR"
      },
      "source": [
        "### **Finalne modele**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyo1aGoW7zK9"
      },
      "source": [
        "#Xception ostatni blok\n",
        "xception_final_1 = create_model(xception_model, lr=1e-5, dropout=0.3)\n",
        "\n",
        "#Xception dwa ostatnie bloki\n",
        "xception_final_2 = create_model(xception_model2, lr=1e-5, dropout=0.3)\n",
        "\n",
        "#ResNet odmrożony ostatni blok\n",
        "resnet_final_1 = create_model(res_model, lr=1e5, dropout=0.3)\n",
        "\n",
        "#ResNet dwa ostatnie bloki\n",
        "resnet_final_2 = create_model(res_model2, lr=1e5, dropout=0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcGASXsBqQb1",
        "outputId": "f261542d-6493-4971-faa8-89dc90782aae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        }
      },
      "source": [
        "xception_final_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Baza_konwolucyjna (Functiona (None, 2048)              20861480  \n",
            "_________________________________________________________________\n",
            "Warstwa_gesta_1 (Dense)      (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "Porzucenie_1 (Dropout)       (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "Warstwa_gesta_2 (Dense)      (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "Porzucenie_2 (Dropout)       (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "Warstwa_gesta_3 (Dense)      (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "Warstwa_gesta_4 (Dense)      (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "Warstwa_wyjsciowa (Dense)    (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 22,337,577\n",
            "Trainable params: 6,224,897\n",
            "Non-trainable params: 16,112,680\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2mzYyQDzE9X"
      },
      "source": [
        "### **Trening**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zexzR4r57exl",
        "outputId": "1c0176dd-4608-4d0c-a951-21a792f2a4a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "xception_1_history = xception_final_1.fit(train_generator, batch_size=64, validation_data=val_generator, \n",
        "                    steps_per_epoch=42, validation_steps=1, validation_batch_size=50, epochs=50,\n",
        "                    callbacks=callbacks_list_1, class_weight=class_weight)\n",
        "\n",
        "xception_2_history = xception_final_2.fit(train_generator, batch_size=64, validation_data=val_generator, \n",
        "                    steps_per_epoch=42, validation_steps=1, validation_batch_size=50, epochs=50,\n",
        "                    callbacks=callbacks_list_2, class_weight=class_weight)\n",
        "\n",
        "resnet_1_history = resnet_final_1.fit(train_generator, batch_size=64, validation_data=val_generator, \n",
        "                    steps_per_epoch=42, validation_steps=1, validation_batch_size=50, epochs=50,\n",
        "                    callbacks=callbacks_list_3, class_weight=class_weight)\n",
        "\n",
        "resnet_2_history = resnet_final_2.fit(train_generator, batch_size=64, validation_data=val_generator, \n",
        "                    steps_per_epoch=42, validation_steps=1, validation_batch_size=50, epochs=50,\n",
        "                    callbacks=callbacks_list_4, class_weight=class_weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "42/42 [==============================] - 681s 16s/step - loss: 1.1271 - binary_accuracy: 0.6754 - val_loss: 0.6558 - val_binary_accuracy: 0.6400\n",
            "Epoch 2/50\n",
            "42/42 [==============================] - 705s 17s/step - loss: 0.9981 - binary_accuracy: 0.6248 - val_loss: 0.6051 - val_binary_accuracy: 0.8000\n",
            "Epoch 3/50\n",
            "42/42 [==============================] - 708s 17s/step - loss: 0.9416 - binary_accuracy: 0.6955 - val_loss: 0.5549 - val_binary_accuracy: 0.8000\n",
            "Epoch 4/50\n",
            "42/42 [==============================] - 699s 17s/step - loss: 0.8982 - binary_accuracy: 0.6974 - val_loss: 0.5186 - val_binary_accuracy: 0.7400\n",
            "Epoch 5/50\n",
            "42/42 [==============================] - 701s 17s/step - loss: 0.8447 - binary_accuracy: 0.7601 - val_loss: 0.4666 - val_binary_accuracy: 0.8000\n",
            "Epoch 6/50\n",
            "42/42 [==============================] - 712s 17s/step - loss: 0.7715 - binary_accuracy: 0.7832 - val_loss: 0.4007 - val_binary_accuracy: 0.8200\n",
            "Epoch 7/50\n",
            "42/42 [==============================] - 708s 17s/step - loss: 0.7202 - binary_accuracy: 0.7749 - val_loss: 0.3365 - val_binary_accuracy: 0.9000\n",
            "Epoch 8/50\n",
            "42/42 [==============================] - 709s 17s/step - loss: 0.6320 - binary_accuracy: 0.8066 - val_loss: 0.3417 - val_binary_accuracy: 0.8800\n",
            "Epoch 9/50\n",
            "42/42 [==============================] - 696s 17s/step - loss: 0.5332 - binary_accuracy: 0.8479 - val_loss: 0.2858 - val_binary_accuracy: 0.9000\n",
            "Epoch 10/50\n",
            "42/42 [==============================] - 702s 17s/step - loss: 0.5212 - binary_accuracy: 0.8597 - val_loss: 0.3099 - val_binary_accuracy: 0.9000\n",
            "Epoch 11/50\n",
            "42/42 [==============================] - 691s 16s/step - loss: 0.4629 - binary_accuracy: 0.8647 - val_loss: 0.2572 - val_binary_accuracy: 0.9000\n",
            "Epoch 12/50\n",
            "42/42 [==============================] - 711s 17s/step - loss: 0.3987 - binary_accuracy: 0.8926 - val_loss: 0.2505 - val_binary_accuracy: 0.9200\n",
            "Epoch 13/50\n",
            "42/42 [==============================] - 714s 17s/step - loss: 0.3654 - binary_accuracy: 0.9119 - val_loss: 0.2444 - val_binary_accuracy: 0.9200\n",
            "Epoch 14/50\n",
            "42/42 [==============================] - 713s 17s/step - loss: 0.3413 - binary_accuracy: 0.9130 - val_loss: 0.2326 - val_binary_accuracy: 0.9200\n",
            "Epoch 15/50\n",
            "42/42 [==============================] - 714s 17s/step - loss: 0.2987 - binary_accuracy: 0.9294 - val_loss: 0.1660 - val_binary_accuracy: 0.9200\n",
            "Epoch 16/50\n",
            "42/42 [==============================] - 707s 17s/step - loss: 0.2778 - binary_accuracy: 0.9263 - val_loss: 0.1671 - val_binary_accuracy: 0.9200\n",
            "Epoch 17/50\n",
            "42/42 [==============================] - 708s 17s/step - loss: 0.2857 - binary_accuracy: 0.9243 - val_loss: 0.1346 - val_binary_accuracy: 0.9200\n",
            "Epoch 18/50\n",
            "42/42 [==============================] - 704s 17s/step - loss: 0.2545 - binary_accuracy: 0.9376 - val_loss: 0.1255 - val_binary_accuracy: 0.9200\n",
            "Epoch 19/50\n",
            "42/42 [==============================] - 694s 17s/step - loss: 0.2133 - binary_accuracy: 0.9463 - val_loss: 0.0912 - val_binary_accuracy: 0.9600\n",
            "Epoch 20/50\n",
            "42/42 [==============================] - 701s 17s/step - loss: 0.2231 - binary_accuracy: 0.9438 - val_loss: 0.1103 - val_binary_accuracy: 0.9400\n",
            "Epoch 21/50\n",
            "42/42 [==============================] - 707s 17s/step - loss: 0.2021 - binary_accuracy: 0.9550 - val_loss: 0.0571 - val_binary_accuracy: 0.9800\n",
            "Epoch 22/50\n",
            "42/42 [==============================] - 701s 17s/step - loss: 0.2095 - binary_accuracy: 0.9461 - val_loss: 0.0728 - val_binary_accuracy: 0.9600\n",
            "Epoch 23/50\n",
            "42/42 [==============================] - 704s 17s/step - loss: 0.1904 - binary_accuracy: 0.9543 - val_loss: 0.0651 - val_binary_accuracy: 0.9800\n",
            "Epoch 24/50\n",
            "42/42 [==============================] - 705s 17s/step - loss: 0.1792 - binary_accuracy: 0.9569 - val_loss: 0.0398 - val_binary_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "42/42 [==============================] - 709s 17s/step - loss: 0.1651 - binary_accuracy: 0.9552 - val_loss: 0.0418 - val_binary_accuracy: 0.9800\n",
            "Epoch 26/50\n",
            "42/42 [==============================] - 714s 17s/step - loss: 0.1861 - binary_accuracy: 0.9557 - val_loss: 0.0290 - val_binary_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "42/42 [==============================] - 708s 17s/step - loss: 0.1637 - binary_accuracy: 0.9586 - val_loss: 0.0324 - val_binary_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "42/42 [==============================] - 711s 17s/step - loss: 0.1410 - binary_accuracy: 0.9601 - val_loss: 0.0467 - val_binary_accuracy: 0.9800\n",
            "Epoch 29/50\n",
            "42/42 [==============================] - 693s 16s/step - loss: 0.1280 - binary_accuracy: 0.9633 - val_loss: 0.0465 - val_binary_accuracy: 0.9800\n",
            "Epoch 30/50\n",
            "42/42 [==============================] - 696s 17s/step - loss: 0.1472 - binary_accuracy: 0.9715 - val_loss: 0.0193 - val_binary_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "30/42 [====================>.........] - ETA: 3:16 - loss: 0.1433 - binary_accuracy: 0.9543"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODJE3OZ50vOY"
      },
      "source": [
        "### **Testowanie oraz ewaluacja wyników**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp7ijTvu_AnW"
      },
      "source": [
        "y_test = [e for e in test_generator.labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h-UgsasQlME"
      },
      "source": [
        "path_xception_1 = '/content/drive/My Drive/mgr/xception_1/xception_1.h5'\n",
        "path_xception_2 = '/content/drive/My Drive/mgr/xception_2/xception_2.h5'\n",
        "\n",
        "path_resnet_1 = '/content/drive/My Drive/mgr/ResNet_1/resnet_1.h5'\n",
        "path_resnet_2 = '/content/drive/My Drive/mgr/resnet_2/resnet_2.h5'\n",
        "\n",
        "\n",
        "xception_1 = load_model(path_xception_1)\n",
        "xception_2 = load_model(path_xception_2)\n",
        "resnet_1 = load_model(path_resnet_1)\n",
        "resnet_2 = load_model(path_resnet_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbzKwZhSL0fk",
        "outputId": "bdc560a8-faf9-47e4-d644-a6b1c0d18b93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "y_pred_xception_1 = (xception_1.predict(test_generator) >= 0.5).astype(\"int32\")\n",
        "y_pred_xception_2 = (xception_2.predict(test_generator) >= 0.5).astype(\"int32\")\n",
        "\n",
        "y_pred_resnet_1 = (resnet_1.predict(test_generator) >= 0.5).astype(\"int32\")\n",
        "y_pred_resnet_2 = (resnet_2.predict(test_generator) >= 0.5).astype(\"int32\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-30d28521cf18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred_xception_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxception_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m    101\u001b[0m           method.__name__))\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1561\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    777\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   def _handle_multiprocessing(self, x, workers, use_multiprocessing,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[1;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;31m# if image is not already an 8-bit, 16-bit or 32-bit grayscale image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgQi5LgtNICE"
      },
      "source": [
        "summary(y_test, y_pred_xception_1)\n",
        "summary(y_test, y_pred_xception_2)\n",
        "\n",
        "summary(y_test, y_pred_resnet_1)\n",
        "summary(y_test, y_pred_resnet_2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPPWuzHz_-7K"
      },
      "source": [
        "training = pd.read_csv('/content/drive/My Drive/results.csv', sep=';')\n",
        "training = training[:].astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLgTLkA0M-wN"
      },
      "source": [
        "plt.style.use('ggplot')\n",
        "plt.figure(figsize=(12,8))\n",
        "#plt.title('Strata - Resnet50',fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Epoka')\n",
        "plt.ylabel('Dokładność', rotation=90)\n",
        "plt.plot(training['x1_Acc'], lw=3, label='Xception_1')\n",
        "plt.plot(training['x2_Acc'], lw=3, label='Xception_2')\n",
        "plt.plot(training['r1_Acc'], lw=3, label='ResNet_1')\n",
        "plt.plot(training['r2_Acc'], lw=3, label='ResNet_2')\n",
        "plt.plot()\n",
        "plt.legend(loc=4, prop = {'size':14})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF122C56b3Sc"
      },
      "source": [
        "plt.style.use('ggplot')\n",
        "plt.figure(figsize=(12,8))\n",
        "#plt.title('Strata - Resnet50',fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Epoka')\n",
        "plt.ylabel('Strata', rotation=90)\n",
        "plt.plot(training['x_1_Loss'], lw=3, label='Xception_1')\n",
        "plt.plot(training['x2_Loss'], lw=3, label='Xception_2')\n",
        "plt.plot(training['r1_Loss'], lw=3, label='ResNet_1')\n",
        "plt.plot(training['r2_Loss'], lw=3, label='ResNet_2')\n",
        "plt.legend(loc=1, prop = {'size':14})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWMLqFrggYhT"
      },
      "source": [
        "plt.style.use('ggplot')\n",
        "plt.figure(figsize=(12,8))\n",
        "#plt.title('Strata - Resnet50',fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Epoka')\n",
        "plt.ylabel('Dokładność', rotation=90)\n",
        "plt.plot(training['x1_Val_acc'], lw=3, label='Xception_1')\n",
        "plt.plot(training['x2_Val_acc'], lw=3, label='Xception_2')\n",
        "plt.plot(training['r1_Val_acc'], lw=3, label='ResNet_1')\n",
        "plt.plot(training['r2_Val_acc'], lw=3, label='ResNet_2')\n",
        "plt.plot()\n",
        "plt.legend(loc=4, prop = {'size':14})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH35TjBw3Aze"
      },
      "source": [
        "plt.style.use('ggplot')\n",
        "plt.figure(figsize=(12,8))\n",
        "#plt.title('Strata - Resnet50',fontsize=16, fontweight='bold')\n",
        "plt.xlabel('Epoka')\n",
        "plt.ylabel('Strata', rotation=90)\n",
        "plt.plot(training['x1_Val_loss'], lw=3, label='Xception_1')\n",
        "plt.plot(training['x2_Val_loss'], lw=3, label='Xception_2')\n",
        "plt.plot(training['r1_Val_loss'], lw=3, label='ResNet_1')\n",
        "plt.plot(training['r2_Val_loss'], lw=3, label='ResNet_2')\n",
        "plt.ylim(0,10)\n",
        "plt.legend(loc=4, prop = {'size':14})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGQ9IpEuS0k2"
      },
      "source": [
        "plt.style.use('ggplot')\n",
        "plt.figure(figsize=(12,8))\n",
        "auc1 = roc_auc_score(y_test, y_pred_xception_1)\n",
        "auc2 = roc_auc_score(y_test, y_pred_xception_2)\n",
        "auc3 = roc_auc_score(y_test, y_pred_resnet_1)\n",
        "auc4 = roc_auc_score(y_test, y_pred_resnet_2)\n",
        "plt.figure(figsize=(12,8))\n",
        "fpr1, tpr1, thresholds = roc_curve(y_test, y_pred_xception_1)\n",
        "fpr2, tpr2, thresholds = roc_curve(y_test, y_pred_xception_2)\n",
        "fpr3, tpr3, thresholds = roc_curve(y_test, y_pred_resnet_1)\n",
        "fpr4, tpr4, thresholds = roc_curve(y_test, y_pred_resnet_2)\n",
        "\n",
        "plt.plot(fpr1, tpr1, label='Xception_1 (AUC = %0.4f)' % auc1, lw=3)\n",
        "plt.plot(fpr2, tpr2, label='Xception_2 (AUC = %0.4f)' % auc2, lw=3)\n",
        "plt.plot(fpr3, tpr3, label='ResNet_1 (AUC = %0.4f)' % auc3, lw=3)\n",
        "plt.plot(fpr4, tpr4, label='ResNet_2 (AUC = %0.4f)' % auc3, lw=3)\n",
        "plt.legend()\n",
        "plt.xlabel('1 - specyficzność')\n",
        "plt.ylabel('Czułość');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G7rq_1NhoSb"
      },
      "source": [
        "precision_x1, recall_x1, _ = precision_recall_curve(y_test, y_pred_xception_1)\n",
        "auc1 = auc(recall_x1, precision_x1)\n",
        "\n",
        "precision_x2, recall_x2, _ = precision_recall_curve(y_test, y_pred_xception_2)\n",
        "auc2 = auc(recall_x2, precision_x2)\n",
        "\n",
        "precision_r1, recall_r1, _ = precision_recall_curve(y_test, y_pred_resnet_1)\n",
        "auc3 = auc(recall_r1, precision_r1)\n",
        "\n",
        "precision_r2, recall_r2, _ = precision_recall_curve(y_test, y_pred_resnet_2)\n",
        "auc4 = auc(recall_r2, precision_r2)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "fpr1, tpr1, thresholds = precision_recall_curve(y_test, y_pred_xception_1)\n",
        "fpr2, tpr2, thresholds = precision_recall_curve(y_test, y_pred_xception_2)\n",
        "fpr3, tpr3, thresholds = precision_recall_curve(y_test, y_pred_resnet_1)\n",
        "plt.\n",
        "plt.plot(precision_x1, recall_x1, label='Xception_1 (AUC = %0.4f)' % auc1, lw=3)\n",
        "plt.plot(precision_x2, recall_x2, label='Xception_2 (AUC = %0.4f)' % auc2, lw=3)\n",
        "plt.plot(precision_r1, recall_r1, label='ResNet_1 (AUC = %0.4f)' % auc3, lw=3)\n",
        "plt.plot(precision_r2, recall_r2, label='ResNet_2 (AUC = %0.4f)' % auc4, lw=3)\n",
        "plt.legend()\n",
        "plt.xlabel('Czułość')\n",
        "plt.ylabel('Precyzja');"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}